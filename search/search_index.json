{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"FRC Game Piece Position Estimation","text":"<p>A fast, robust, and field-ready algorithm for real-time object pose estimation in FRC.</p> <p>This project provides a complete, open-source pipeline for estimating the real-world position and orientation of FRC game pieces from camera images. It uses a data-driven image-matching approach, offering extremely fast and accurate pose estimation\u2014optimized for Raspberry Pi deployment in real-world matches.</p> <p>The algorithm is designed for fixed-camera setups and leverages a precomputed dataset of synthetic images rendered in Blender. During runtime, it matches live camera frames to this dataset to infer the pose of the game piece in under 10 milliseconds.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li> <p>High-Speed &amp; Accuracy   Matches live camera images to a precomputed dataset of rendered frames for sub-10ms pose estimation.</p> </li> <li> <p>Fully Explained, Fully Open   Includes all source code, rendering tools, and clear documentation of each stage\u2014perfect for learning, customization, or direct use.</p> </li> <li> <p>Modular, Multi-Process Architecture   Ensures real-time performance by offloading detection, estimation, and networking to separate processes.</p> </li> <li> <p>Built for FRC Robots   Seamless integration with FRC systems via NetworkTables, optimized for Raspberry Pi or similar edge devices.</p> </li> </ul>"},{"location":"#how-it-works","title":"How It Works","text":""},{"location":"#preprocessing-one-time-offline","title":"Preprocessing (One-Time, Offline)","text":"<ul> <li>Render thousands of labeled images in Blender using the provided scripts.</li> <li>Each frame encodes the 3D pose of the game piece from a fixed camera viewpoint.</li> <li>Store the dataset in CSV format with pose metadata.</li> </ul>"},{"location":"#runtime-on-robot","title":"Runtime (On-Robot)","text":"<ul> <li>Capture live frames from the robot\u2019s fixed-position camera.</li> <li>Detect the game piece using either simple color filtering or ML-based segmentation.</li> <li>Extract bounding rectangles and (optionally) orientation info.</li> <li>Find the closest match in the dataset using a fast image similarity search.</li> <li>Output the real-world position and orientation of the game piece.</li> </ul> <p>Step-by-Step Setup Guide</p> <p>For detailed setup instructions, Blender configuration, and usage examples, see the Step-by-Step Guide.</p>"},{"location":"setup/","title":"Game Piece Position Estimation - Step by step guide","text":"<p>Welcome! This guide walks you through setting up the project, generating images with Blender, processing data, and using the pose estimation algorithm to predict a game piece\u2019s position relative to a robot.</p>"},{"location":"setup/#prerequisites","title":"Prerequisites","text":"<ul> <li>Operating system: Windows, macOS, or Linux</li> <li>Python: 3.10+ (3.11 recommended)</li> <li>Blender: 4.5 or newer (older versions may fail to open the provided <code>.blend</code> file)</li> <li>Git (optional, for cloning)</li> </ul> <p>Python installation</p> <p>If Python isn't installed, please install it first, you can use this guide: Python installation guide.</p> <p>After installation, ensure <code>python</code>/<code>pip</code> are available from your terminal.</p>"},{"location":"setup/#download-the-project","title":"Download the project","text":"Using GitDownload ZIP <pre><code># Navigate to the folder where you want the repository\ncd &lt;PATH_TO_YOUR_CODE_FOLDER&gt;\n\n# Clone the repository\ngit clone https://github.com/YoavRozov/FRC-Game-Piece-Pos-Estimation.git\n</code></pre> <ol> <li>Click Code \u2192 Download ZIP on the repository page.</li> <li>After the download completes, extract the ZIP to your desired folder.</li> </ol>"},{"location":"setup/#program-setup-python","title":"Program setup (Python)","text":"<p>Open a terminal/command prompt and navigate to the project folder you cloned/extracted in the previous step.</p> Windows (PowerShell/CMD)macOS / Linux (Bash) <pre><code>cd &lt;PATH_TO_PROJECT_ROOT&gt;\n</code></pre> <pre><code>cd &lt;PATH_TO_PROJECT_ROOT&gt;\n</code></pre>"},{"location":"setup/#recommended-create-a-virtual-environment","title":"(Recommended) Create a virtual environment","text":"WindowsmacOS / Linux <pre><code>python -m venv .venv\n.venv\\Scripts\\activate\n</code></pre> <pre><code>python -m venv .venv\nsource .venv/bin/activate\n</code></pre>"},{"location":"setup/#install-required-packages","title":"Install required packages","text":"<p>From the project root:</p> <pre><code>pip install -r requirements.txt\n</code></pre>"},{"location":"setup/#blender","title":"Blender","text":"<ol> <li>Download and install Blender from: blender.org</li> <li>Open the <code>template.blend</code> file included in this repository.</li> </ol> <p>Warning</p> <p>If the file doesn't open, ensure you're using Blender 4.5 or newer. Older versions may not be compatible.</p>"},{"location":"setup/#setup-blender-python-packages","title":"Setup Blender-Python packages","text":"<ol> <li>In Blender, click Windows \u2192 Toggle System Console so you can see script output.</li> <li>Navigate to the Scripting tab.</li> <li>In the script drop-down, select <code>Install requirements</code>.</li> <li>Click Run and verify there are no errors in the console.</li> </ol>    Your browser does not support the video tag."},{"location":"setup/#blender-setup-image-generation","title":"Blender setup &amp; Image Generation","text":""},{"location":"setup/#41-capture-reference-images","title":"4.1 Capture reference images","text":"<p>Connect your robot's camera to your computer.</p> <p>Run the <code>image_capture.py</code> script and capture a few photos with the game piece clearly in frame. These will be used to calibrate the camera.</p> <p>Tip</p> <p>Take these photos on a floor with a tile grid pattern (e.g., a classroom floor). Aligning Blender\u2019s grid to a real grid makes calibration much easier.</p>"},{"location":"setup/#42-calibrate-the-camera-in-blender","title":"4.2 Calibrate the camera in Blender","text":"<ol> <li>Open <code>template.blend</code>.</li> <li>Measure your robot\u2019s camera height above the ground and its rotation.</li> <li>Click the camera icon (in the viewport) to view through the camera.</li> <li>Select the camera in the Outliner.<ul> <li>Open Object Data Properties \u2192 Background Images, enable it, and load one of the photos captured in the last step.</li> <li>Adjust position and rotation under Object Properties.</li> <li>Adjust Field of View and Sensor Size under Object Data Properties.</li> </ul> </li> <li>Align the camera so Blender\u2019s grid matches the floor\u2019s grid in your background image. You can also modify Blender\u2019s grid size to match the physical tile size on your floor.</li> </ol> <p>Optional: fSpy for a head start</p> <p>You can use fSpy to get a close initial camera estimate. Helpful video tutorials:</p> <ul> <li>How to Install fSpy Photo Matching Software</li> <li>How to Install the fSpy Importer Add-on for Blender</li> <li>How to Match a Photo with fSpy</li> </ul>    Your browser does not support the video tag."},{"location":"setup/#43-import-the-game-piece-model","title":"4.3 Import the game piece model","text":"<ol> <li>Download the official game piece model (e.g., from FIRST\u2019s website) and export/save it as <code>.stl</code> from SolidWorks.</li> <li>In Blender: File \u2192 Import \u2192 STL, select the saved model.</li> <li>After import, you will likely need to scale by 0.001 (1/1000) because SolidWorks uses millimeters and Blender uses meters.</li> <li>With the object selected, open Object Properties \u2192 Scale and set the scale.</li> <li>Press <code>F3</code>, search for <code>Origin to Geometry</code>, and press Enter to center the origin.</li> </ol>    Your browser does not support the video tag."},{"location":"setup/#44-define-the-working-area-with-fov_plane","title":"4.4 Define the working area with <code>FOV_Plane</code>","text":"<ol> <li>Open the Camera Plane Set Up tab.</li> <li>Click the camera icon (in the viewport) to switch to the camera\u2019s view.</li> <li>As you can see the viewport is split so you have a left (camera view) and right (top-down) view.</li> <li>In the left view, use Move (from the top toolbar). In the right/top view:<ul> <li>Select the plane object named <code>FOV_Plane</code>.</li> <li>Press <code>Tab</code> to enter Edit Mode.</li> <li>Select vertices and move them along X and Y to match the camera FOV visible in the left view.</li> </ul> </li> </ol> <p>Tip</p> <p>Use <code>s</code> \u2192 <code>x</code> on your keyboard to scale two or more vertices on the x axis.</p>    Your browser does not support the video tag."},{"location":"setup/#45-run-the-main-blender-script","title":"4.5 Run the main Blender script","text":"<ol> <li>Select the imported game piece, go to Material Properties and select the <code>Red</code> material</li> <li>Windows \u2192 Toggle System Console (if not already open) to view outputs.</li> <li>Go to the Scripting tab and select the <code>main</code> file from the dropdown.</li> <li>Review configuration variables at the top of the script and adjust as needed.</li> <li>Run the script and wait for rendering to complete.</li> </ol>    Your browser does not support the video tag."},{"location":"setup/#process-blender-data","title":"Process Blender data","text":"<p>After rendering finishes, open the <code>ProcessBlenderData.ipynb</code> Jupyter notebook and run all cells.</p> <p>Output: a <code>CSV</code> containing all possible game piece positions and their bounding rectangles in the generated images.</p>"},{"location":"setup/#estimate-the-position","title":"Estimate the position","text":"<p>Open the <code>PoseEstimation.ipynb</code> notebook to accurately predict the game piece\u2019s position relative to the robot given the bounding rectangle in an image.</p> <p>Note</p> <p>For a production-ready example, see the <code>RaspberryPiCode/</code> folder for integrating the algorithm on-device.</p>"},{"location":"setup/#troubleshooting","title":"Troubleshooting","text":"<p>Blender file won\u2019t open Ensure you\u2019re using Blender 4.4+. Update Blender if necessary.</p> <p><code>pip install -r requirements.txt</code> fails</p> <ul> <li>Activate your virtual environment first.  </li> <li>Upgrade pip: <code>python -m pip install --upgrade pip</code> </li> <li>On macOS/Linux, try <code>pip3</code> instead of <code>pip</code> if multiple Python versions exist.</li> </ul> <p>Background image won\u2019t show in camera view</p> <ul> <li>Confirm you enabled Background Images in Object Data Properties for the camera.  </li> <li>Check the opacity and that you\u2019re actually viewing through the camera.</li> </ul> <p>Imported STL is too big/small</p> <ul> <li>SolidWorks uses mm, Blender uses m. Scale by 0.001 or 1000 accordingly.  </li> <li>Apply scale if needed (<code>Ctrl+A \u2192 Scale</code>).</li> </ul> <p><code>main</code> script can\u2019t find paths/files</p> <ul> <li>Confirm paths are correct and files exist in the expected folders.  </li> <li>Run Blender from the project root or adjust path handling in the script.</li> </ul>"},{"location":"setup/#attributions","title":"Attributions","text":"<ul> <li>Blender\u00ae is a registered trademark of the Blender Foundation.</li> <li>fSpy is a community project for camera matching.</li> <li>FIRST\u00ae references for the game piece model.</li> </ul>"}]}